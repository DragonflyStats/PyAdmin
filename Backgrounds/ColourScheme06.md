18/06/2016 16:40:14	Allen Thomas Varghese	allentv4u@gmail.com	Full Stack Developer and Community Engagement Specialist at Creme Global	Technology generalist with 7+ years of professional IT experience, organises technology events around data science and programming. Technology mentor, advisor and speaker. Love small ideas that have a big impact.	I've used Python a lot, just recently	I was a PyCon 2015 speaker on the topic "Creating add ons for Blender in Python"	ie.linkedin.com/in/allentv	Python Data Science	Introduction to Pandas library	Data Science	The workshop will give an introduction to the Pandas library. The content is based on the iPython notebooks available on the Pandas documentation website. There would be small snippets of code that would be added to the existing content to make it more easier to follow. One or more case studies of how data munging can be done would be covered if time permits. Only basic python knowledge is assumed. The Anaconda distribution would be used to setup the environment and Jupyter notebooks would be used to run the code snippets. All code would be made available on Github before the event - github.com/allentv	Beginner	An introduction into a commonly used third-party technology. (good for beginners)	2 hours		MacBook Pro									
24/06/2016 15:44:49	Sean O'Donnell	sean@odonnell.nu	Technical Architect	Founder of Python Ireland, Python Developer for 13 years, currently Chief Technical Architect at RapidRatings	I've used Python a lot, for several years	Yes, I believe I've spoken at 2 Pycon Irelands, and I have lost count of how many meeetups, but not in the last 4 or 5 years.	@seanodonnell	General Python or Python based Frameworks	Practical Django Debugging and Profiling	A Tour of common tools and techniques to deal with broken or slow Django Code	I plan to cover Debug Mode, The Django Debug Toolbar, The Werkzeug Debugger,  Profiling Middleware, Logging and Locust for Load testing. The Goal is to introduce each tool, give its pros and cons, and a short demonstration. Ideally there will be enough time for some Q&A at the end.	Beginner	An introduction into a niche area of Python or a niche library/technology.	I can tailor the talk to anything between 30 and 50 mins 	No	Nothing Special, Laptop, Projector									
06/07/2016 11:03:27	Eoin Brazil	eoin.brazil@gmail.com	Senior Proactive Technical Services Engineer MongoDB	"Eoin works at MongoDB working on proactive support helping clients using MongoDB and writing Python to perform detection potential customer deployment issues in the MongoDB SaaS/DBaaS platform (misconfiguration, time series analysis, anomaly detection). He previously worked in research commercialisation and led teams in TSSG (mobile services) and ICHEC (HPC/parallel programming) focused on commercial consultancy projects. He spent almost a decade as a researcher in interaction design. He has given talks on topics from machine learning to behaviour design to mobile services and HPC.

Eoin holds a BSc in Computer Systems from UL, a PGDip in Technology Commercialisation from NUIG as well as a MSc and a PhD in Computer Science from UL."	I've used Python a lot, for several years	I spoke last year at PyConIE on the PyData track talking about data pipelines with Python and MongoDB http://lanyrd.com/2015/pyconie/sdrkdq/	eoinbrazil	General Python or Python based Frameworks	Python and MongoDB for Geo-applications	Using the geo query framework in MongoDB in your Python application for geo-query	Using the geo query framework in MongoDB in your Python application for geo-query. The goal of this talk is to provide a simple example on Github that folks can follow in the talk and then download later. Geo-spatial queries can easily by integrated into your Python application using MongoDB and this talk will walk through several examples on how to do. It'll also walk through how you can use the Aggregation Framework with geo-queries (e.g. what's the next X nearest items to this specific item in terms of distance).	Beginner	An introduction into a commonly used third-party technology. (good for beginners)	30 Mins		Similar to last year, my own laptop and a Github repo for the talk plus code examples									
06/07/2016 11:19:43	Eoin Brazil	eoin.brazil@gmail.com	Senior Proactive Technical Services Engineer MongoDB	"Eoin works at MongoDB working on proactive support helping clients using MongoDB and writing Python to perform detection potential customer deployment issues in the MongoDB SaaS/DBaaS platform (misconfiguration, time series analysis, anomaly detection). He previously worked in research commercialisation and led teams in TSSG (mobile services) and ICHEC (HPC/parallel programming) focused on commercial consultancy projects. He spent almost a decade as a researcher in interaction design. He has given talks on topics from machine learning to behaviour design to mobile services and HPC.

Eoin holds a BSc in Computer Systems from UL, a PGDip in Technology Commercialisation from NUIG as well as a MSc and a PhD in Computer Science from UL."	I haven't used Python much	I spoke last year at PyConIE on the PyData track talking about data pipelines with Python and MongoDB http://lanyrd.com/2015/pyconie/sdrkdq/	eoinbrazil	Python Data Science	Gradient boosting: What is it and How can I use in my machine learning ?	This talk aims to introduce the technique and explore the advantages/disadvantages of it plus the various Python packages available for it	Gradient boosting is a very popular technique in Machine Learning and particularly so for competitions like those hosted by Kaggle. This talk will provide an introduction to the technique, a short historical recap and then focus on the existing libraries in Python that allow you to use this general family. It'll work through the advantages and disadvantage of specific libraries using worked examples. The code and slides will be in Github. The end learning of attendees will be sufficient knowledge to understand when to use this technique and what is the most appropriate Python library for their needs.	Intermediate	An introduction into a niche area of Python or a niche library/technology.	30 Mins		Same as last year, my own laptop with the resource on Github									
06/07/2016 12:12:35	Allen Thomas Varghese	allentv4u@gmail.com	Full Stack Developer and Community Engagement Specialist at CremeGlobal	Organizer of technology meetups in Dublin for data science (Dublin Data Science for Beginners, Data Scientists Ireland) and for teaching programming (Codecademy Dublin). Speaker at workshops and mentor at technology events. Works as Full Stack Developer and Community Engagement Specialist at CremeGlobal developing predictive modelling software for Food Safety, Nutrition, Cosmetics and Microbial sectors using Python PyData stack.	I've used Python a lot, just recently	PyCon Ireland 2015, Workshop: Creating add-ons for Blender	ie.linkedin.com/in/allentv, @allentv4u	General Python or Python based Frameworks	Supercharging with Collections	Python Data Structures	Data structures are an integral part of any software. They help you manage data effectively and also help with fast data access which in turn improves the software performance. The collections package in Python has some handy and high performance data structures that are built upon the available dict, list, set and tuple data types. The talk will give an introduction to some of these data types and explain how it is used with code samples.	Beginner	An introduction into a commonly used third-party technology. (good for beginners)	30 Mins		MacBook									
06/07/2016 12:15:31	Allen Thomas Varghese	allentv4u@gmail.com	Full Stack Developer and Community Engagement Specialist at CremeGlobal	Organizer of technology meetups in Dublin for data science (Dublin Data Science for Beginners, Data Scientists Ireland) and for teaching programming (Codecademy Dublin). Speaker at workshops and mentor at technology events. Works as Full Stack Developer and Community Engagement Specialist at CremeGlobal developing predictive modelling software for Food Safety, Nutrition, Cosmetics and Microbial sectors using Python PyData stack.	I've used Python a lot, just recently	PyCon Ireland 2015, Workshop: Creating add-ons for Blender	ie.linkedin.com/in/allentv, @allentv4u	General Python or Python based Frameworks	Mocking in Unit Testing	Unit Testing	Unit testing is a major part of any software development process. Writing unit tests sometimes is a frustrating process and many put it off for later for meeting deadlines. This would affect code quality and have an adverse impact on the codebase especially when feature requests happen often. This talk introduces the python mock library that makes writing unit tests easier and resilient to change. An introduction to the mock library would be covered and code samples.	Beginner	An introduction into a commonly used third-party technology. (good for beginners)	30 Mins		MacBook									
06/07/2016 12:20:16	Allen Thomas Varghese	allentv4u@gmail.com	Full Stack Developer and Community Engagement Specialist at CremeGlobal	Organizer of technology meetups in Dublin for data science (Dublin Data Science for Beginners, Data Scientists Ireland) and for teaching programming (Codecademy Dublin). Speaker at workshops and mentor at technology events. Works as Full Stack Developer and Community Engagement Specialist at CremeGlobal developing predictive modelling software for Food Safety, Nutrition, Cosmetics and Microbial sectors using Python PyData stack.	I've used Python a lot, just recently	PyCon Ireland 2015, Workshop: Creating add-ons for Blender	ie.linkedin.com/in/allentv, @allentv4u	General Python or Python based Frameworks	My Journey: Barista to Pythonista	General Python	I had switched programming languages from Java to Python in the last 2 years. This talk is about some of the bumps that I faced during the transition. Both languages have its strengths and this talk will focus on the comparison of different features and I why they add value to a programmer’s toolbox.	Beginner	Features of the Python language	30 Mins		MacBook									
11/07/2016 15:21:02	Jose Dominguez	josmasflores@gmail.com	PhD candidate	Software contractor and PhD candidate in wearable sensors for health	I've used Python on-and-off over several years	Nope	https://twitter.com/josmasflores	Python Data Science	Introduction to Image classification in Python: from API calls to Neural Networks	Data science, machine learning for image classification in Python	"In a world full of user generated media content, automated image and video processing plays a prominent role, both in social media apps (face, object, and place detection), and in local applications that automatically sort media collections, among other uses.

In the last few years, a number of startups such as Clarifai and Indico, and much bigger players such as Google and Microsoft, have launched their own 'machine learning as a service' offerings, including 'vision' products that can recognise objects present in image and video footage and automatically tag them, provide optical character recognition (OCR) services, and even not safe for work (NSFW) classifiers that can be used to omit content from internal networks.

This talk will focus on 'food' recognition within images, and will walk through the basics of how to get started with image classification, from using APIs and SDKs for some of the commercial (but free) offerings available, to trying and recreate those services locally, first by walking through and example of the 'bag of features' technique, using a mix of supervised and unsupervised methods in scikit-learn and OpenCV, and secondly showing examples based on 'transfer learning', a 'deep learning' technique to reuse pre-trained convolutional neural networks to customise classification from smaller training datasets."	Intermediate	An introduction into a niche area of Python or a niche library/technology.	30 Mins	Not really	Projector and clicker									
13/07/2016 09:54:50	Paul O'Grady	paul.ogrady@gmail.com	Data Scientist/Engineer @ Zalando	Comp. Sci. Ph.D / Pythonista / Dubliner (& Python Ireland committee member.)	I've used Python a lot, for several years	Gave a talk at PyConIE in 2012 & 2015	http://twitter.com/paul_ogrady	Python Data Science	Detection of Duplicate Records in Large-scale Multi-tenant Platforms	Data Science 	"Zalando's quest to create an open multi-tenant fashion platform has its challenges. One of these is the detection of duplicate product records within the platform, where different tenants input the same product using different product descriptions. Commonly referred to as the *Record Linkage* problem in Machine Learning, the task is to group together similar product records under a single canonical identifier, which is useful for business intelligence purposes and for product search etc. The kernel of the solution is the computation of an ~O(n**2) all-pairs similarity join, where the runtime explodes quadratically with an increase in input.

At Zalando's Fashion Insight Centre in Dublin we are looking at solutions to this problem that work at scale (i.e., more than one million products). For our particular problem, which involves Categorical Data (cosine similarity will not work here), we employ a data-driven similarity measure and approximate the similarity join using a two-step approach. In this talk we introduce the standard approaches to the problem and illustrate our work-to-date using Python."	Intermediate	An insight into tackling DS problems at scale.	30 Mins	Saturday Afternoon	Laptop									
13/07/2016 14:09:13	Mick Cooney	mickcooney@gmail.com	Quantitative Analyst	"Co-organiser of Dublin R and Dublin Julia - I've worked as a jack-of-all-trades in various roles in financial services for the last 10 years or so.

I run regular workshops and give the odd talk for Dublin R"	I've used Python on-and-off over several years	No. I have given regular talks for Dublin R and Julia though	https://www.github.com/kaybenleroll/dublin_r_workshops	General Data Science	Measuring Uncertainty - Comparing the Bootstrap, MCMC and ADVI for Linear Models	Data Science	"A crucial but often-overlooked aspect of predictive and statistical modelling is estimating the uncertainty in your prediction or forecast.

Various approaches are made to handle this issue, the simplest of which is to add standard errors around point forecasts. This approach requires strong underlying assumptions for the data.

Better methods involve bootstrapping the data and running multiple instances of the modelling on each bootstrap sample and estimating the uncertainty that way. An alternative approach is to take a Bayesian approach and use Markov Chain Monte Carlo (MCMC) to sample of the posterior distribution conditioned on the data. Often computationally expensive MCMC tool have begun introducing a related optimisation-based approach known as Automatic Differentiation Variational Inference (ADVI).

In this talk I will introduce and compare the three approaches in a three cases: a simple 'flat' linear model, a poisson process and a hierarchical model (the 8 schools dataset).

In all cases we will compare the outputs of the various approaches and attempt to benchmark performance of the algorithms in terms of simplicity, execution speed, memory usage and prediction. We also assess how effective the various approaches are at capturing the uncertainty in the modelling process.

The talk is likely to include both R and Python code as well as the use of Stan for MCMC sampling and ADVI.

(by all means get in touch with me if you want more detail or would prefer I shift the focus a little)"	Intermediate	An insight in how to capture uncertainty into modelling (good for everyone)	45 - 50 Mins	Any time is fine for me	I can bring a laptop if you need me to - will probably put everything into PDF if a computer is provided for presentation									
13/07/2016 21:01:49	Ian Huston	ian@ianhuston.net	Data Scientist	Ian started out as a theoretical physicist, moved into data science a few years ago and is now part of the data science team at Pivotal Labs, the agile software consulting arm of Pivotal. Ian has worked on a variety of customer engagements at Pivotal including catastrophe risk modelling, fashion & consumer analytics, factory production quality and online marketing. Ian has been building analytical and numerical models for about 10 years and started out building high performance computing models of the earliest moments of the universe after the Big Bang. 	I've used Python a lot, for several years	"Strata Santa Clara (2014) 
CF Summit (2015)
PyData NY (2014) 
PyData London (2014, 2015)
Python Ireland meetup (2015) 
Open Data Science Conference (Invited Speaker, California Nov 2015)
Data Science London meetup (various)
Cloud Native Applications London meetup 2015
Data Science Lab meetup
London Quant Finance meetup
"	@ianhuston	General Data Science	How Data Science fits in the Balanced Team	Data Science	"The goal of a Balanced Team is to share ownership and responsibility for the success of a project between team members. Each team member has specific obligations to the team and a specific area of authority. Until recently, designers, product managers and developers were the usual team members considered. In this talk I will explore how data scientists can function in a balanced team and discuss my experience working as a data scientist on balanced teams at Pivotal Labs with our global clients. I will consider what obligations and authority a data scientist can provide as part of a balanced team and how this situation differs from the usual jack-of-all-trades type data science work.

I will outline specific examples where data science can help user centric design and product management, and where the practices of lean-startup and agile development can help accelerate analysis and data science. Based on my experience building data science driven products with a global bank and European car manufacturers, I will outline what we tried, what worked and most importantly what didn’t.

If you are a data scientist or need to work with one, this talk will equip you to understand how data science can be an integral part of a balanced team.
"	Beginner	An insight into our community. (good for everyone)	30 Mins		Macbook + Powerpoint									
15/07/2016 09:12:10	Paul Barry	paul.barry@itcarlow.ie	Lecturer	Paul Barry has lectured at the Institute of Technology, Carlow for more years than he cares to mention. Paul's also a bone fide technology author, having written books for Wiley and O'Reilly Media. His latest, a from-the-ground-up rewrite of Head First Python, should be published by the time PyCon Ireland 2016 opens its doors (Paul's rewrite is already 4 years late, but let's not mention that: he promises the wait *will* be worth it). As part of his day-job, Paul teaches Python to undergraduate and postgraduate computing students at IT Carlow. Paul also uses Python "for real" with start-up and consultancy projects.	I've used Python a lot, for several years	Yes: at 2015, 2012, 2011, and 2010.	http://paulbarry.itcarlow.ie   @barrypj	Python Data Science	A Bluffer's Guide to Data Science	Data Science	A light-hearted look at the world of Data Science for Python programmers who are eyeing-up the Data Science problem domain and thinking: "It can't be all that hard, can it?".  In his talk, Paul presents his thinking on what Python programmers need to know in order to convincingly pass themselves off as a "real" Data Scientist.	Everyone.	Introduction to Data Science for Python Programmers	30 Mins	No.	Map laptop (with VGA/HDMI output).									
15/07/2016 09:23:47	Paul Barry	paul.barry@itcarlow.ie	Lecturer	Paul Barry has lectured at the Institute of Technology, Carlow for more years than he cares to mention. Paul's also a bone fide technology author, having written books for Wiley and O'Reilly Media. His latest, a from-the-ground-up rewrite of Head First Python, should be published by the time PyCon Ireland 2016 opens its doors (Paul's rewrite is already 4 years late, but let's not mention that: he promises the wait *will* be worth it). As part of his day-job, Paul teaches Python to undergraduate and postgraduate computing students at IT Carlow. Paul also uses Python "for real" with start-up and consultancy projects.	I've used Python a lot, for several years	Yes: at 2015, 2012, 2011, and 2010.	http://paulbarry.itcarlow.ie   @barrypj	General Python or Python based Frameworks	Try, try, and try again.	Python Exception Handling	Everyone agrees that writing code in Python is easier than most other programming languages. It's easy to knock-up something quickly to solve most problems, which is great if all your code is "throw-away". Python's great at not getting in your way: you write your code, it runs, then you move onto something else. But, how easy is to to write robust code in Python, that is: code which has to hang around for a long time? What if you need to write code which not only runs but also has to handle problems should they occur? In this talk, Paul presents some working code, then talks about the things that can go wrong with the code, before describing the language constructs that Python provides to help programmers handle (and survive) the identified problems.	Beginner	An introduction into some commonly used parts of Python. (good for beginners)	30 Mins	No.	Mac Laptop (VGA/HDMI output).									
15/07/2016 15:43:13	Michael McKerns	mmckerns@uqfoundation.org	Computational Scientist	Mike has been a research scientist at Caltech since 2002, and is co-founder of the UQ Foundation, a non-profit for the advancement of predictive science. Mike is the author several python packages, including mystic (highly-constrained non-convex optimization and uncertainty quantification), pathos (parallel graph management and execution in heterogeneous computing), and dill (serialize all of python). His software is the backbone of several research projects on risk analysis and predictive science, and is leveraged by packages in machine learning and parallel computing. He has over fifteen years of teaching experience, has given hundreds of conference and workshop presentations, and has taught over fifty week-long Python training classes in the past four years.	I've used Python a lot, for several years	I have given hundreds of conference and workshop presentations. At PyConIE, I have presented at least one talk or workshop each of the past two years.	https://github.com/mmckerns	Python Data Science	Using the mystic framework to accelerate data science	data science, numerical optimization, and parallel computing	"In business analytics, operations research, engineering design, and other predictive sciences, a critical step in building models of reality and making predictions is solving an optimization problem.  Reality is high-dimensional, nonlinear, and often probabilistic -- while optimizers are typically at best either nonlinear or high-dimensional, and rarely are probabilistic. Thus, we are often forced to solve reduced-dimensional problems that may no longer adequately represent reality. This talk will introduce some new tools for solving high-dimensional non-convex optimization problems with nonlinear constraints.

In this talk I’ll begin with traditional optimization methods, then show how to extend these methods to solve high-dimensional non-convex optimization problems with highly nonlinear constraints using the mystic framework.

I’ll start by introducing the cost function, and it’s use in local and global optimization. I’ll then address how to monitor and diagnose optimization convergence and results, tune an optimizer, and customize optimizer stop conditions. Traditionally, optimizers have been limited in their ability to apply constraining information, in that certain algorithms provide box constraints while others provide built-in penalty functions. Very often when constraints can be applied, they are limited to either quadratic or linear constraints.  I’ll discuss how to build robust penalty functions and symbolic constraints equations, and demonstrate new methods to efficiently reduce optimizer search space. I’ll also discuss how to apply statistical and probabilistic constraints.

Real-world inverse problems are expensive, thus I’ll show several ways to accelerate optimization through asynchronous and parallel computing. This talk will demonstrate how efficiency in optimization workflow can be dramatically increased by solver restarts, saving of state, results caching and archiving, and automated dimensional reduction. Next I will discuss new hyper-optimization methods that leverage parallel computing to perform fast global optimizations and n-dimensional global searches. Can your favorite optimizer discover all local extrema on an unknown potential energy surface in a single invocation? mystic can.

The audience need not be an expert in optimization, but should have interest in solving hard real-world optimization problems.  The audience should walk away with a working knowledge of how to use modern constrained optimization tools, how to enable their solvers to leverage high-performance parallel computing, and how to utilize legacy data and surrogate models in statistical and predictive modeling.

For more information about mystic, see: http://pythonhosted.org/mystic and https://github.com/uqfoundation/mystic."	Intermediate	An introduction into a niche area of Python or a niche library/technology.	30 Mins	No	laptop, projector									
15/07/2016 15:55:41	Michael McKerns	mmckerns@uqfoundation.org	Computational Scientist	Mike has been a research scientist at Caltech since 2002, and is co-founder of the UQ Foundation, a non-profit for the advancement of predictive science. Mike is the author several python packages, including mystic (highly-constrained non-convex optimization and uncertainty quantification), pathos (parallel graph management and execution in heterogeneous computing), and dill (serialize all of python). His software is the backbone of several research projects on risk analysis and predictive science, and is leveraged by packages in machine learning and parallel computing. He has over fifteen years of teaching experience, has given hundreds of conference and workshop presentations, and has taught over fifty week-long Python training classes in the past four years.	I've used Python a lot, for several years	I have given hundreds of conference and workshop presentations. At PyConIE, I have presented at least one talk or workshop each of the past two years.	https://github.com/mmckerns	Parallel computing in Python	Scalable Hierarchical Parallel Computing	efficiency, parallel computing	"This tutorial is targeted at the intermediate-to-advanced Python user who wants to extend Python into hierarchical parallel computing. The tutorial will provide hands-on examples and essential performance tips every developer should know for writing effective parallel Python. The result will be a clear sense of possibilities and best practices using Python in simple parallel computing environments.

Many of the examples you often find on parallel Python focus on the mechanics of getting the parallel infrastructure working with your code, and not on actually building good portable parallel Python. This tutorial is intended to be a broad introduction to writing high-performance parallel Python that is well suited to both the beginner and the veteran developer. Parallel efficiency starts with the speed of the target code itself, so we will start with how to evolve code from for-loops to Python looping constructs and vector programming. We will also discuss tools and techniques to optimize your code for speed and memory performance.

The tutorial will overview working with the common parallel communication technologies (threading and multiprocessing) and introduce the use of parallel programming models such as blocking and non-blocking pipes, asynchronous and iterative conditional maps, and map-reduce. We will discuss strategies for extending parallel workflow to utilize hierarchical and heterogeneous computing, distributed parallel computing, and job schedulers.

At the end of the tutorial, participants should be able to write simple parallel Python scripts, make use of effective parallel programming techniques, and have a framework in place to leverage the power of Python in parallel computing environments.

OUTLINE:
~~ parallel programming ~~ 
* vector programming vs looping constructs
* timing, profiling, and code optimization
* coding for speed and portability
* scalability with asynchronous computing
* Exercise(s)
~~ multiprocessing and threads ~~ 
* point to point communication
* blocking and non-blocking (iterative, unordered, and asynchronous) communication
* task pools and collective communication
* issues: serialization, working in __main__
* Exercise(s)
~~ distributed parallel computing ~~
* point to point communication
* blocking and non-blocking (iterative, unordered, and asynchronous) communication
* task pools and collective communication
* issues: serialization and heterogeneity
* issues: failure detection and reporting
* Exercise(s)
~~ hierarchical workflow ~~
* workflow management
* server-client computing
* cluster schedulers
* ssh-tunneling
* Exercise(s)

PREREQUISITES:
This tutorial will assume attendees have basic knowledge of python and numpy. The tutorial will require python, numpy, and pathos to be installed. All packages can be installed under Anaconda or Canopy, with setuptools or pip, and may also be installed with Linux or Macintosh package managers.

PRELIMINARY MATERIALS and DOCUMENTATION:
An earlier version of the tutorial is available at: http://www.pyvideo.org/video/1345/efficient-parallel-python-for-high-performance-co while a preliminary version of the tutorial is at https://github.com/mmckerns/tuthpc."	Intermediate	An introduction into a niche area of Python or a niche library/technology.	120 Mins	No	laptop, projector									
15/07/2016 16:02:10	Michael McKerns	mmckerns@uqfoundation.org	Computational Scientist	Mike has been a research scientist at Caltech since 2002, and is co-founder of the UQ Foundation, a non-profit for the advancement of predictive science. Mike is the author several python packages, including mystic (highly-constrained non-convex optimization and uncertainty quantification), pathos (parallel graph management and execution in heterogeneous computing), and dill (serialize all of python). His software is the backbone of several research projects on risk analysis and predictive science, and is leveraged by packages in machine learning and parallel computing. He has over fifteen years of teaching experience, has given hundreds of conference and workshop presentations, and has taught over fifty week-long Python training classes in the past four years.	I've used Python a lot, for several years	I have given hundreds of conference and workshop presentations. At PyConIE, I have presented at least one talk or workshop each of the past two years.	https://github.com/mmckerns	Parallel computing in Python	Shared-Memory High-Performance Parallel Computing 	Parallel computing in Python	"This tutorial is targeted at the intermediate-to-advanced Python user who wants to extend Python into high-performance computing. The tutorial will provide hands-on examples and essential performance tips every developer should know for writing effective parallel Python. The result will be a clear sense of possibilities and best practices using Python in HPC environments.

Many of the examples you often find on parallel Python focus on the mechanics of getting the parallel infrastructure working with your code, and not on actually building good portable parallel Python. This tutorial is intended to be a broad introduction to writing high-performance parallel Python that is well suited to both the beginner and the veteran developer. Parallel efficiency starts with the speed of the target code itself, so we discuss tools and techniques to optimize your code for speed and memory performance. We will then compare code in for-loops versus Python looping constructs and vector programming.

The tutorial will overview working with the common parallel communication technologies (threading, multiprocessing, MPI) and introduce the use of parallel programming models such as blocking and non-blocking pipes, and locks and asynchronous communication. We will discuss strategies for extending parallel workflow to utilize common communication patterns for shared memory constructs. We then return our focus to the speeding up our target code by leveraging parallelism within compiled code using cython.

At the end of the tutorial, participants should be able to write simple parallel Python scripts, make use of parallel programming techniques, and have a framework in place to leverage the power of Python in high-performance computing.

OUTLINE:
~~ parallel programming ~~ 
* vector programming vs looping constructs
* timing, profiling, and code optimization
* coding for speed and portability
* skirting the GIL (ctypes and shared memory)
* Exercise(s)
~~ multiprocessing and threading ~~ 
* pipes and queues, locks and synchronization
* blocking and non-blocking communication
* shared memory and shared objects
* issues: thread-locking and collisions
* Exercise(s)
~~ mpi4py ~~ 
* pipes and queues, locks and synchronization
* blocking and non-blocking communication
* shared memory and shared objects
* issues: MPI and python imports, resource allocation 
* Exercise(s)
~~ cython~~ 
* building extension modules 
* adding type declarations
* leveraging external functions, structures, and classes
* accessing native parallelism (numpy and nogil)
* Exercise(s)

PREREQUISITES:
This tutorial will assume attendees have basic knowledge of python and numpy. The tutorial will require python, numpy, mpi4py, and cython to be installed. All packages can be installed under Anaconda or Canopy, with setuptools or pip, and may also be installed with Linux or Macintosh package managers.

PRELIMINARY MATERIALS and DOCUMENTATION:
An earlier version of the tutorial is available at: http://www.pyvideo.org/video/1345/efficient-parallel-python-for-high-performance-co while a preliminary version of the tutorial is at https://github.com/mmckerns/tuthpc."	Advanced	An introduction into a niche area of Python or a niche library/technology.	120 Mins	No	laptop, projector									
15/07/2016 16:12:45	davide poggiali	poggiali.davide@gmail.com	PhD student	"Last year PhD student in Neuroscience in Padua, Italy.  
I got my Degree in Mathematics in 2012 with thesis on medical image reconstruction, then I decided to study Neuroimaging, with focus on MRI and PET/MRI of patients with Multiple Sclerosis, Alzheimer's  Disease, Brain Tumor and other neurological disorders.
As an enthusiastic python user, I write my own code any time it's possible to have complete control over the computation of neurological biomarkes."	I've used Python a lot, just recently	I never did	http://dpoggiali.altervista.org/	Python Data Science	Data Analysis in MRI and PET/MRI Neuroimaging	Neuroimaging in python	Since the introduction of new hybrid systems as PET/MRI and due to the constant increase of MRI sequences, neuroimaging datasets are growing constantly. Nowadays a Neurological research study has to be considered a big data problem. In this talk I will introduce from scratch some of the most common algorithms for computing neuroimaging biomarkers and give some ideas about efficiency increasing. Some examples in python will be given.	Intermediate	An introduction into a niche area of Python or a niche library/technology.	30 Mins	In the morning it would be better	my Macbook									
15/07/2016 16:23:33	Michael McKerns	mmckerns@uqfoundation.org	Computational Scientist	Mike has been a research scientist at Caltech since 2002, and is co-founder of the UQ Foundation, a non-profit for the advancement of predictive science. Mike is the author several python packages, including mystic (highly-constrained non-convex optimization and uncertainty quantification), pathos (parallel graph management and execution in heterogeneous computing), and dill (serialize all of python). His software is the backbone of several research projects on risk analysis and predictive science, and is leveraged by packages in machine learning and parallel computing. He has over fifteen years of teaching experience, has given hundreds of conference and workshop presentations, and has taught over fifty week-long Python training classes in the past four years.	I've used Python a lot, for several years	I have given hundreds of conference and workshop presentations. At PyConIE, I have presented at least one talk or workshop each of the past two years.	https://github.com/mmckerns	Python Data Science	New Tools for Constrained Nonlinear Optimizations and Kernel Transformations	numerical optimization, data science, and parallel computing	"Highly-constrained, large-dimensional, and nonlinear optimizations are found at the root of most of today’s forefront problems in risk, operations research, materials design, and other predictive sciences. This tutorial will introduce modern tools for solving optimization problems -- beginning with traditional methods, and extending to solving high-dimensional non-convex optimization problems with highly nonlinear constraints. We will start by introducing the cost function, and it’s use in local and global optimization. We will then address how to monitor and diagnose your optimization convergence and results, tune your optimizer, and utilize compound termination conditions. This tutorial will discuss building and applying box constraints, penalty functions, and symbolic constraints. We will then demonstrate methods to efficiently reduce search space through the use of robust optimization constraints.  Real-world inverse problems can be expensive, thus we will show how to enable your optimization to seamlessly leverage parallel computing. This tutorial will cover using asynchronous computing for results caching and archiving, dynamic real-time optimization, and dimensional reduction. Next we will discuss new hyper-optimization methods that leverage parallel computing to perform fast global optimizations and n-dimensional global searches. We will then learn how to apply statistical and probabilistic constraints, and put that knowledge into use in solving applications of global optimization in statistical and data sciences.

The audience need not be an expert in optimization, but should have interest in solving hard real-world optimization problems.  We will begin with a walk through some introductory optimizations, learning how to build confidence in understanding your results. By the end of the tutorial, participants will have working knowledge of how to use modern constrained optimization tools, how to enable their solvers to leverage high-performance parallel computing, and how to utilize legacy data and surrogate models in statistical and predictive modeling.

OUTLINE:
~~ introduction to optimization ~~
* the cost function
* local and global optimization
* monitoring and diagnosing convergence and optimization results
* solver tuning and compound termination conditions
* Exercise(s)
~~ penalty functions and constraints ~~ 
* box constraints
* applying penalty functions
* reducing search space with constraints
* applying symbolic constraints
* Exercise(s)
~~ solver efficiency ~~
* leveraging parallel and asynchronous computing
* ensemble search
* surrogate construction
* dimensional reduction
* Exercise(s)
~~ statistical and probabilistic constraints~~
* sampling statistics
* sampling distributions
* statistical constraints
* information constraints from legacy data
* optimization with unknown probability distributions
* Exercise(s)
~~ design under uncertainty ~~
* the cost metric
* sensitivity analysis 
* experimental design
* calculating likelihood and probability
* Exercise(s)

PREREQUISITES:
This tutorial will assume attendees have basic knowledge of python and numpy, and is intended for scientific developers who are interested in utilizing optimization to solve real-world problems in statistical and data sciences. The tutorial will require python, numpy, and mystic to be installed, and optionally installs of matplotlib, scipy, and pathos. All packages can be installed under Anaconda or Canopy, or with setuptools or pip.

PRELIMINARY MATERIALS and DOCUMENTATION:
Sample exercises are available at https://github.com/uqfoundation/mystic and https://github.com/uqfoundation/pathos/examples2. A preliminary version of the tutorial is available at: https://github.com/mmckerns/tutmom."	Intermediate	An introduction into a niche area of Python or a niche library/technology.	120 Mins	No	laptop, projector									
15/07/2016 21:46:02	Niall O'Connor	zechs.marquie@gmail.com	Software Developer (team lead) Bank of America	A familiar face at Irish tech events. Has previously given talks and workshops on TDD, BDD, Linked Data and python in general.	I've used Python a lot, for several years	Yep. See bio.	@nialloc1978	General Python or Python based Frameworks	Introduction to Python, Spark & Hadoop	Introducing participants to the use of python, spark and hadoop for large datasets	"Using python to interact with the spark data engine on the hadoop platform.
 
·         What is hadoop.

·         What is spark.

·         What is pyspark.

·         Using pyspark to work with data on HDFS

·         Using pyspark to parallelize computation on a hadoop cluster.

·         Limitations of spark and hadoop.

 
A workshop for python programmers to get familiar with hadoop and spark.  It is assumed you can code and run a python module, that you understand basic data structures.  It is assumed you have hadoop and spark installed."	Intermediate	An introduction into a niche area of Python or a niche library/technology.	4 hours/half day	Saturday Afternoon	Laptop									
17/07/2016 17:54:32	Leonid Vasilyev	vsleonid@gmail.com	SRE	Joined Dropbox as SRE in Dublin a year ago. Working on Dropbox's physical data center and AWS EC2 infrastructure automation. Before worked in AWS for 2.5 years. I'm programming in Python for 8 years now.	I've used Python a lot, for several years	No	https://twitter.com/chingun	General Python or Python based Frameworks	Building Hermetic Python Packages with Bazel @ Dropbox	Shipping Python code in production	"Historically, Dropbox used Encap as a packaging system to deploy custom Python packages to production servers. This approach has a number of issues and limitations. Early this year we started transition to custom build system based on Google's recently open sourced project – Bazel. I'd like to share our experience of building ecosystem around  Bazel and workflow we use to build and package our code that is scalable and robust. 

Draft of Agenda:
Background: [~10 mins]
- Encap intro
- Workflow with encap
- Issues with encap
Migration to Bazel:[~20 mins]
- Bazel intro
- Hermetic packages
- Managing Pypi/C dependencies
- Workflow with Bazel
- Wins/Issues with Bazel
- Future work"	Intermediate	An introduction into a commonly used third-party technology. (good for beginners), A detailed look at a niche library/technology., An insight into the Python ecosystem. (good for everyone)	30 Mins		MacBook Pro/Keynote slides + iterm2  demo									
17/07/2016 21:57:55	Ronan Hayes	ronan.hayes@teamaol.com	Automation Engineer	Automation Engineer on the AOL Adtech team	I've used Python on-and-off over several years	No	www.linkedin.com/in/batmansdad	General Python or Python based Frameworks	Lazy Automation : Get your code to do your job	Automation with sprinkles of introspection and bigdata	"“I choose a lazy person to do a hard job. Because a lazy person will find an easy way to do it.”

In the AOL Adtech team we have some creative/easy ways to test our systems. This workshop will showcase two key points:

1. How to get your code to generate your unit and integration tests
2. How to get your customers to generate even more tests

The workshop will go into detail on:

1. Modelling your interfaces and data
2. Using introspection and JINJA2 to generate tests
3 . Using the Elastic stack to monitor and collect data
4. Leveraging data to generate more test cases.

The workshop will assume a beginner level of python and introduce each library and technology . The net result is a very simple and easy step by step guide to getting your code to do your job."	Beginner	An introduction into some commonly used parts of Python. (good for beginners), An introduction into a commonly used third-party technology. (good for beginners), An introduction into a niche area of Python or a niche library/technology., A detailed look at a niche library/technology.	45 - 50 Mins	No	Laptop, projector, websites									
18/07/2016 14:01:47	Mick Cooney	mickcooney@gmail.com	Quantitative Analysis	Same as my other submission (which I forgot to save)	I've used Python on-and-off over several years	I speak a lot at Dublin R, and have given presentations at a bunch of other meetups, but never for Python Ireland.	@kaybenleroll	General Data Science	Introduction to Survival Analysis	data science	"Survival analysis, and time to event modelling in general, is a well established field in areas such as medical statistics and a few other places but has never really made the jump over to machine learning.

In this talk I will talk about the basic of survival analysis and show how to implement various survival models in both R and Python. I will discuss some of the pitfalls and gotchas, and will show its use in areas such as churn analysis."	Intermediate	An introduction into a niche area of Python or a niche library/technology., A detailed look at a niche library/technology.	45 - 50 Mins	I'm good for any configuration / duration or timeslot that works	Laptop									
18/07/2016 23:44:35	Humberto Corona	hcorona@gmail.com	Data Scienctist	I am a Data Scientist at Zalando, previously Insight UCD. My research interests are recommender systems, and machine learning applied to music. 	I've used Python a lot, just recently	no	http://hcorona.github.io , https://www.linkedin.com/in/humberto-corona-86394328	General Data Science	sharing knowledge in the python ecosystem 	data science, jupyter, github, research	Data Scientists (or researchers) often do many early-stage prototyping and run many experiments before finding the optimal solution for the problem they are trying to solve. However, sometimes, a lot of the knowledge gained in the process stays with the person. In this proposed talk, I would like to introduce how to produce, share and ensure the reproducibility of experiments using jupyter notebooks and github. This is a series of lessons Iearned while being a research student (where open-sourcing the code and data used to generate papers is very important) and more recently, working in a new team in Zalando, where we have experimented with different ways to share and review the data science tasks, as well as the knowledge generated from those tasks. 	Beginner	An insight into the Python ecosystem. (good for everyone), An insight into our community. (good for everyone)	between 15 and 30 mins	no	laptop + internet 									
